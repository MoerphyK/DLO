{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = \"cpu\"\n",
    "print(f\"CUDA available? {torch.cuda.is_available()}\")\n",
    "from torchvision import datasets\n",
    "from torch.optim import SGD\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "from pretty_confusion_matrix import pp_matrix\n",
    "from pretty_confusion_matrix import pp_matrix_from_data\n",
    "\n",
    "from PIL import Image as im\n",
    "from IPython.display import Image, display\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and load the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = datasets.MNIST('data/', download=True, train=True)\n",
    "train_images = train_set.data\n",
    "train_targets = train_set.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = datasets.MNIST('data/', download=True, train=False)\n",
    "test_images = test_set.data\n",
    "test_targets = test_set.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        x = x.float()/255\n",
    "        x = x.view(-1,28*28)\n",
    "        self.x, self.y = x, y\n",
    "    def __getitem__(self, ix):\n",
    "        x, y = self.x[ix], self.y[ix]\n",
    "        return x.to(device), y.to(device)\n",
    "    def __len__(self):\n",
    "        return len(self.x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_to_image(data_element,index,true):\n",
    "    array = data_element.numpy()\n",
    "    array = array * 255\n",
    "\n",
    "    array = np.reshape(array, (28, 28))\n",
    "    im_data = im.fromarray(array)\n",
    "    im_data.convert('RGB').save(f'failed/{index}_number{true}.png', \"PNG\", optimize=True)\n",
    "    display(Image(filename=f'failed/{index}_number{true}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train = MNISTDataset(train_images, train_targets)\n",
    "    train_dl = DataLoader(train, batch_size=32, shuffle=True)\n",
    "    test = MNISTDataset(test_images, test_targets)\n",
    "    test_dl = DataLoader(test, batch_size=len(test_images), shuffle=True)\n",
    "    # test_dl = DataLoader(test, batch_size=10, shuffle=True)\n",
    "    return train_dl, test_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(28 * 28, 70),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(70, 35),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(35, 15),\n",
    "        nn.Sigmoid(),\n",
    "        nn.Linear(15, 10)\n",
    "    ).to(device)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = SGD(model.parameters(), lr=15e-2)\n",
    "    return model, loss_fn, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_batch(x, y, model, opt, loss_fn):\n",
    "    model.train()\n",
    "    prediction = model(x)\n",
    "    batch_loss = loss_fn(prediction, y)\n",
    "    batch_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    return batch_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def accuracy(x, y, model):\n",
    "    with torch.no_grad():\n",
    "        prediction = model(x)\n",
    "    max_values, argmaxes = prediction.max(-1)\n",
    "    is_correct = argmaxes == y\n",
    "    return is_correct.cpu().numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def loss(x, y, model):\n",
    "    prediction = model(x)\n",
    "    loss = loss_fn(prediction, y)\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl = get_data()\n",
    "model, loss_fn, optimizer = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear old images\n",
    "dir = 'failed/'\n",
    "for f in os.listdir(dir):\n",
    "    os.remove(os.path.join(dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------------------------\n",
    "# Test >>>\n",
    "#\n",
    "\n",
    "model.load_state_dict(torch.load(\"nnMnist_40h_20h.ph\", map_location='cpu'))\n",
    "model.eval() # Was macht eval? \n",
    "'''\n",
    "Remember that you must call model.eval() to set dropout and batch normalization layers to evaluation mode before running inference.\n",
    "Failing to do this will yield inconsistent inference results.\n",
    "'''\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "\n",
    "for data, target in test_dl:\n",
    "   data, target = data.to(device), target.to(device)\n",
    "   output = model(data)\n",
    "   pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "    \n",
    "   y_pred.extend(pred.data.cpu().numpy())\n",
    "   y_true.extend(target.data.cpu().numpy())\n",
    "\n",
    "   counter = 0\n",
    "   for i in range(len(y_pred)):\n",
    "      if y_pred[i][0] != y_true[i]:\n",
    "         data_to_image(data[i],counter,y_true[i])\n",
    "         print(f\"Pred/Target: {y_pred[i][0]} / {y_true[i]}\")\n",
    "         counter += 1\n",
    "\n",
    "# pp_matrix_from_data(y_true, y_pred, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ----------------------------------------------\n",
    "## Training >>>\n",
    "##\n",
    "\n",
    "# print('Starting training...')\n",
    "\n",
    "# time0 = timer()\n",
    "\n",
    "# epochs = 40\n",
    "\n",
    "# arrPlotX = []\n",
    "# train_losses, train_accuracies = [], []\n",
    "# test_losses, test_accuracies = [], []\n",
    "# for epoch in range(epochs):\n",
    "#     train_epoch_losses, train_epoch_accuracies = [], []\n",
    "#     for ix, batch in enumerate(iter(train_dl)):\n",
    "#         x, y = batch\n",
    "#         batch_loss = train_batch(x, y, model, optimizer, loss_fn)\n",
    "#         train_epoch_losses.append(batch_loss)\n",
    "#     train_epoch_loss = np.array(train_epoch_losses).mean()\n",
    "#     for ix, batch in enumerate(iter(train_dl)):\n",
    "#         x, y = batch\n",
    "#         is_correct = accuracy(x, y, model)\n",
    "#         train_epoch_accuracies.extend(is_correct)\n",
    "#     train_epoch_accuracy = np.mean(train_epoch_accuracies)\n",
    "#     for ix, batch in enumerate(iter(test_dl)):\n",
    "#         x, y = batch\n",
    "#         val_is_correct = accuracy(x, y, model)\n",
    "#         validation_loss = loss(x, y, model)\n",
    "#     val_epoch_accuracy = np.mean(val_is_correct)\n",
    "#     arrPlotX.append(epoch)\n",
    "#     train_losses.append(train_epoch_loss)\n",
    "#     train_accuracies.append(train_epoch_accuracy)\n",
    "#     test_losses.append(validation_loss)\n",
    "#     test_accuracies.append(val_epoch_accuracy)\n",
    "#     print( f\"epoch: {epoch}  train_acc: {100 * train_epoch_accuracy:.2f}%  test_acc: {100 * val_epoch_accuracy:.2f}%\" )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"nnMnist_40h_20h.ph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.grid(color='black', linestyle='-', linewidth=0.5)\n",
    "plt.plot(arrPlotX, train_accuracies,\"b\",label='Training')\n",
    "plt.legend()\n",
    "plt.plot(arrPlotX, test_accuracies,\"r\", label='Testing')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"accuracies.png\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
